{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bzo96fXUnB4i"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle\n",
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install diffusers accelerate peft datasets wandb ftfy tensorboard datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/huggingface/diffusers\n",
        "%cd /content/diffusers/examples/text_to_image"
      ],
      "metadata": {
        "id": "6RMr_zoTH0S2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "HVOsDhzdH91u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/finetuningoutput"
      ],
      "metadata": {
        "id": "JWYlWx2OIPdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kv7iU7BCo1zc"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7An7_ZFdpMva"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d markminerov/88500-car-images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFqCpfjYpsrK"
      },
      "outputs": [],
      "source": [
        "!unzip 88500-car-images.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h47DXER4p5So"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "dataset_dir = '/content/out'\n",
        "print(os.listdir(dataset_dir)[:10])\n",
        "\n",
        "# Load and display an image\n",
        "image_path = os.path.join(dataset_dir, '1.jpg')\n",
        "image = Image.open(image_path)\n",
        "image.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JApKb03Cq3ZE"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "files = os.listdir(dataset_dir)\n",
        "\n",
        "# Display the first 1-2 images\n",
        "for file in files[:2]:\n",
        "    image_path = os.path.join(dataset_dir, file)\n",
        "    image = Image.open(image_path)\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')  # Hide the axis\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HurTodVXuTl7"
      },
      "outputs": [],
      "source": [
        "!pip install accelerate diffusers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPZ6rAyhrOFX"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoProcessor, LlavaForConditionalGeneration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xr01lZqhrSy0"
      },
      "outputs": [],
      "source": [
        "# Load the model and processor\n",
        "model = LlavaForConditionalGeneration.from_pretrained(\"llava-hf/llava-1.5-7b-hf\")\n",
        "processor = AutoProcessor.from_pretrained(\"llava-hf/llava-1.5-7b-hf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DJBVmLFuCbj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "# Move the model to GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJTcoY3wuKZe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baGUOR8osRsV"
      },
      "outputs": [],
      "source": [
        "image_path = os.path.join(dataset_dir, files[15])\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# Define the prompt\n",
        "prompt = \"USER: <image>\\nDescribe what car is this including the brand, color and type. ASSISTANT:\"\n",
        "\n",
        "# Prepare inputs for the model\n",
        "inputs = processor(text=prompt, images=image, return_tensors=\"pt\")\n",
        "inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "# Generate the description\n",
        "generate_ids = model.generate(**inputs, max_new_tokens=50)\n",
        "description = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
        "\n",
        "print(description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qe2Aj71tka3g"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(files, columns=['file_name'])\n",
        "sampled_df = df.sample(n=200, random_state=42).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18Hs0FeX_7MX"
      },
      "outputs": [],
      "source": [
        "dataset_dir = '/content/out'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVZLWZL1kx9f"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import json\n",
        "from io import BytesIO\n",
        "def extract_assistant_message(text):\n",
        "    return text.split(\"ASSISTANT:\")[-1].strip()\n",
        "\n",
        "results = []\n",
        "\n",
        "for index, row in sampled_df.iterrows():\n",
        "    image_path = os.path.join(dataset_dir, row['file_name'])\n",
        "    image = Image.open(image_path)\n",
        "    buffered = BytesIO()\n",
        "    image.save(buffered, format=\"JPEG\")\n",
        "    encoded_image = base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
        "\n",
        "    # Generate caption for the image\n",
        "    inputs = processor(text=prompt, images=image, return_tensors=\"pt\")\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "    generate_ids = model.generate(**inputs, max_new_tokens=50)\n",
        "    full_text = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
        "    description = extract_assistant_message(full_text)\n",
        "    results.append({'image': encoded_image, 'text': description})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NNQszZSmBgks"
      },
      "outputs": [],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvKOqL0uAM7c"
      },
      "outputs": [],
      "source": [
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "features = Features({\n",
        "    'image': Value('string'),\n",
        "    'text': Value('string')\n",
        "})\n",
        "\n",
        "dataset_new = Dataset.from_pandas(df, features=features)\n",
        "print(dataset_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMcQb1AoAg4K"
      },
      "outputs": [],
      "source": [
        "dataset_new.push_to_hub(\"Vibhav99/150-sampled-car-images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBOH0bVYk7zn"
      },
      "outputs": [],
      "source": [
        "# Initialize lists to store results\n",
        "file_names = []\n",
        "descriptions = []\n",
        "\n",
        "for index, row in sampled_df.iterrows():\n",
        "    image_path = os.path.join(dataset_dir, row['file_name'])\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "    inputs = processor(text=prompt, images=image, return_tensors=\"pt\")\n",
        "\n",
        "    generate_ids = model.generate(**inputs, max_new_tokens=50)\n",
        "    description = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
        "\n",
        "    file_names.append(row['file_name'])\n",
        "    descriptions.append(description)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVAjcLJCMaDs"
      },
      "outputs": [],
      "source": [
        "ft_df = results_df\n",
        "# Function to extract the assistant's message\n",
        "def extract_assistant_message(text):\n",
        "    return text.split(\"ASSISTANT:\")[-1].strip()\n",
        "\n",
        "# Apply the function to the 'text' column\n",
        "ft_df['text'] = results_df['text'].apply(extract_assistant_message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdwaep9RK-YK"
      },
      "outputs": [],
      "source": [
        "# Function to display image with its description\n",
        "def display_image_with_description(image_path, description):\n",
        "    image = Image.open(image_path)\n",
        "    plt.imshow(image)\n",
        "    plt.title(description)\n",
        "    plt.axis('off')  # Hide the axis\n",
        "    plt.show()\n",
        "\n",
        "# Display the first 5 images with descriptions as an example\n",
        "for index, row in ft_df[4:6].iterrows():\n",
        "    image_path = os.path.join(dataset_dir, row['image'])\n",
        "    display_image_with_description(image_path, row['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3RhwPBDjMz5J"
      },
      "outputs": [],
      "source": [
        "# Define the path to save the file in Google Drive\n",
        "save_path = '/content/drive/My Drive/PixArt_FT_cars.csv'\n",
        "\n",
        "# Save the DataFrame to the specified path\n",
        "ft_df.to_csv(save_path, index=False)\n",
        "\n",
        "print(f\"Dataset with descriptions saved to '{save_path}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RP-26o0N1KL"
      },
      "source": [
        "Loading PixArt-alpha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SB0Jy7exNE5a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from diffusers import PixArtAlphaPipeline\n",
        "pipe = PixArtAlphaPipeline.from_pretrained(\"PixArt-alpha/PixArt-XL-2-512x512\", torch_dtype=torch.float16)\n",
        "pipe = pipe.to(\"cuda\")\n",
        "# if using torch < 2.0\n",
        "# pipe.enable_xformers_memory_efficient_attention()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine-tuning job with Stable Diffusion"
      ],
      "metadata": {
        "id": "w3bpGTy4NVQr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdcK7YiQsy93"
      },
      "outputs": [],
      "source": [
        "!accelerate launch --mixed_precision=\"fp16\"  train_text_to_image_lora.py \\\n",
        "  --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" \\\n",
        "  --dataset_name='Vibhav99/150-sampled-car-images' \\\n",
        "  --resolution=512 --center_crop --random_flip \\\n",
        "  --train_batch_size=1 \\\n",
        "  --gradient_accumulation_steps=4 \\\n",
        "  --max_train_steps=15000 \\\n",
        "  --learning_rate=1e-04 \\\n",
        "  --max_grad_norm=1 \\\n",
        "  --lr_scheduler=\"cosine\" --lr_warmup_steps=0 \\\n",
        "  --output_dir=\"/content/finetuningoutput\" \\\n",
        "  --push_to_hub \\\n",
        "  --report_to=wandb \\\n",
        "  --checkpointing_steps=500 \\\n",
        "  --validation_prompt=\"describe what car is this including the brand, color and type.\" \\\n",
        "  --seed=1337"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51mb_7bZxPlL"
      },
      "outputs": [],
      "source": [
        "dataset.save_to_disk('/content/finetuningoutput/Fine-tuning-data')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}